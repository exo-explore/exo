model_id = "mlx-community/Kimi-K2-Instruct-4bit"
revision = "91fb4f9fd1de100104925196d62b8ee06fd2ad60"
n_layers = 61
hidden_size = 7168
supports_tensor = true
tasks = ["TextGeneration"]
family = "kimi"
quantization = "4bit"
base_model = "Kimi K2"
capabilities = ["text"]

[storage_size]
in_bytes = 620622774272
